# INTEL CONFIDENTIAL
#
# Copyright (C) 2022 Intel Corporation.
#
# This software and the related documents are Intel copyrighted materials, and your use of
# them is governed by the express license under which they were provided to you (License).
# Unless the License provides otherwise, you may not use, modify, copy, publish, distribute,
# disclose or transmit this software or the related documents without Intel's prior written permission.
#
# This software and the related documents are provided as is, with no express or implied warranties,
# other than those that are expressly stated in the License.

---

namespace:
  create: true
  value: dev

dataPath: "/mnt/consul/local-pv-01"
workNodes: "ubuntu-6e58224c2c"
#workNodes: "evifei-Z370-AORUS-Gaming-5"

# whether to create the storage class
scCreate: true
scName: "local-storage"
persistance:
  name: evi-consul-local-pv-nodea-01
# Available parameters and their default values for the Consul chart.
consul:
# Holds values that affect multiple components of the chart.
  global:
    # The main enabled/disabled setting. If true, servers,
    # clients, Consul DNS and the Consul UI will be enabled. Each component can override
    # this default via its component-specific "enabled" config. If false, no components
    # will be installed by default and per-component opt-in is required, such as by
    # setting `server.enabled` to true.
    enabled: true

    # Set the prefix used for all resources in the Helm chart. If not set,
    # the prefix will be `<helm release name>-consul`.
    # @type: string
    name: consul

    # The domain Consul will answer DNS queries for
    # (see `-domain` (https://consul.io/docs/agent/options#_domain)) and the domain services synced from
    # Consul into Kubernetes will have, e.g. `service-name.service.consul`.
    domain: consul

    # The name (and tag) of the Consul Docker image for clients and servers.
    # This can be overridden per component. This should be pinned to a specific
    # version tag, otherwise you may inadvertently upgrade your Consul version.
    #
    # Examples:
    #
    # ```yaml
    # # Consul 1.5.0
    # image: "consul:1.5.0"
    # # Consul Enterprise 1.5.0
    # image: "hashicorp/consul-enterprise:1.5.0-ent"
    # ```
    # @default: hashicorp/consul:<latest version>
    image: "hashicorp/consul:1.14.2"

    # Array of objects containing image pull secret names that will be applied to each service account.
    # This can be used to reference image pull secrets if using a custom consul or consul-k8s Docker image.
    # See https://kubernetes.io/docs/concepts/containers/images/#using-a-private-registry for reference.
    #
    # Example:
    #
    # ```yaml
    # imagePullSecrets:
    #   - name: pull-secret-name
    #   - name: pull-secret-name-2
    # ```
    # @type: array<map>
    imagePullSecrets: []

    # The name (and tag) of the consul-k8s (https://github.com/hashicorp/consul-k8s)
    # Docker image that is used for functionality such the catalog sync.
    # This can be overridden per component.
    # @default: hashicorp/consul-k8s:<latest version>
    imageK8S: "hashicorp/consul-k8s-control-plane:1.0.2"

    # The name of the datacenter that the agents should
    # register as. This can't be changed once the Consul cluster is up and running
    # since Consul doesn't support an automatic way to change this value currently:
    # https://github.com/hashicorp/consul/issues/1858.
    datacenter: dc1

    # Controls whether pod security policies are created for the Consul components
    # created by this chart. See https://kubernetes.io/docs/concepts/policy/pod-security-policy/.
    enablePodSecurityPolicies: false

    # Configures which Kubernetes secret to retrieve Consul's
    # gossip encryption key from (see `-encrypt` (https://consul.io/docs/agent/options#_encrypt)). If secretName or
    # secretKey are not set, gossip encryption will not be enabled. The secret must
    # be in the same namespace that Consul is installed into.
    #
    # The secret can be created by running:
    #
    # ```shell
    # $ kubectl create secret generic consul-gossip-encryption-key --from-literal=key=$(consul keygen)
    # ```
    #
    # To reference, use:
    #
    # ```yaml
    # global:
    #   gossipEncryption:
    #     secretName: consul-gossip-encryption-key
    #     secretKey: key
    # ```
    gossipEncryption:
      # secretName is the name of the Kubernetes secret that holds the gossip
      # encryption key. The secret must be in the same namespace that Consul is installed into.
      secretName: ""
      # secretKey is the key within the Kubernetes secret that holds the gossip
      # encryption key.
      secretKey: ""

    # Enables TLS (https://learn.hashicorp.com/tutorials/consul/tls-encryption-secure)
    # across the cluster to verify authenticity of the Consul servers and clients.
    # Requires Consul v1.4.1+ and consul-k8s v0.16.2+
    tls:
      # If true, the Helm chart will enable TLS for Consul
      # servers and clients and all consul-k8s components, as well as generate certificate
      # authority (optional) and server and client certificates.
      enabled: false

      # If true, turns on the auto-encrypt feature on clients and servers.
      # It also switches consul-k8s components to retrieve the CA from the servers
      # via the API. Requires Consul 1.7.1+ and consul-k8s 0.13.0
      enableAutoEncrypt: false

      # A list of additional DNS names to set as Subject Alternative Names (SANs)
      # in the server certificate. This is useful when you need to access the
      # Consul server(s) externally, for example, if you're using the UI.
      # @type: array<string>
      serverAdditionalDNSSANs: []

      # A list of additional IP addresses to set as Subject Alternative Names (SANs)
      # in the server certificate. This is useful when you need to access the
      # Consul server(s) externally, for example, if you're using the UI.
      # @type: array<string>
      serverAdditionalIPSANs: []

      # If true, `verify_outgoing`, `verify_server_hostname`,
      # and `verify_incoming_rpc` will be set to `true` for Consul servers and clients.
      # Set this to false to incrementally roll out TLS on an existing Consul cluster.
      # Please see https://consul.io/docs/k8s/operations/tls-on-existing-cluster
      # for more details.
      verify: true

      # If true, the Helm chart will configure Consul to disable the HTTP port on
      # both clients and servers and to only accept HTTPS connections.
      httpsOnly: true

      # A Kubernetes secret containing the certificate of the CA to use for
      # TLS communication within the Consul cluster. If you have generated the CA yourself
      # with the consul CLI, you could use the following command to create the secret
      # in Kubernetes:
      #
      # ```bash
      # kubectl create secret generic consul-ca-cert \
      #     --from-file='tls.crt=./consul-agent-ca.pem'
      # ```
      caCert:
        # The name of the Kubernetes secret.
        secretName: null
        # The key of the Kubernetes secret.
        secretKey: null

      # A Kubernetes secret containing the private key of the CA to use for
      # TLS communication within the Consul cluster. If you have generated the CA yourself
      # with the consul CLI, you could use the following command to create the secret
      # in Kubernetes:
      #
      # ```bash
      # kubectl create secret generic consul-ca-key \
      #     --from-file='tls.key=./consul-agent-ca-key.pem'
      # ```
      #
      # Note that we need the CA key so that we can generate server and client certificates.
      # It is particularly important for the client certificates since they need to have host IPs
      # as Subject Alternative Names. In the future, we may support bringing your own server
      # certificates.
      caKey:
        # The name of the Kubernetes secret.
        secretName: null
        # The key of the Kubernetes secret.
        secretKey: null

    # [Enterprise Only] `enableConsulNamespaces` indicates that you are running
    # Consul Enterprise v1.7+ with a valid Consul Enterprise license and would
    # like to make use of configuration beyond registering everything into
    # the `default` Consul namespace. Requires consul-k8s v0.12+. Additional configuration
    # options are found in the `consulNamespaces` section of both the catalog sync
    # and connect injector.
    enableConsulNamespaces: false

    # Configure ACLs.
    acls:

      # If true, the Helm chart will automatically manage ACL tokens and policies
      # for all Consul and consul-k8s components.
      # This requires Consul >= 1.4 and consul-k8s >= 0.14.0.
      manageSystemACLs: false

      # A Kubernetes secret containing the bootstrap token to use for
      # creating policies and tokens for all Consul and consul-k8s components.
      # If set, we will skip ACL bootstrapping of the servers and will only
      # initialize ACLs for the Consul clients and consul-k8s system components.
      # Requires consul-k8s >= 0.14.0.
      bootstrapToken:
        # The name of the Kubernetes secret.
        secretName: null
        # The key of the Kubernetes secret.
        secretKey: null

      # If true, an ACL token will be created that can be used in secondary
      # datacenters for replication. This should only be set to true in the
      # primary datacenter since the replication token must be created from that
      # datacenter.
      # In secondary datacenters, the secret needs to be imported from the primary
      # datacenter and referenced via `global.acls.replicationToken`.
      # Requires consul-k8s >= 0.13.0.
      createReplicationToken: false

      # replicationToken references a secret containing the replication ACL token.
      # This token will be used by secondary datacenters to perform ACL replication
      # and create ACL tokens and policies.
      # This value is ignored if `bootstrapToken` is also set.
      # Requires consul-k8s >= 0.13.0.
      replicationToken:
        # The name of the Kubernetes secret.
        secretName: null
        # The key of the Kubernetes secret.
        secretKey: null

    # Configure federation.
    federation:
      # If enabled, this datacenter will be federation-capable. Only federation
      # via mesh gateways is supported.
      # Mesh gateways and servers will be configured to allow federation.
      # Requires `global.tls.enabled`, `meshGateway.enabled` and `connectInject.enabled`
      # to be true. Requires Consul 1.8+.
      enabled: false

      # If true, the chart will create a Kubernetes secret that can be imported
      # into secondary datacenters so they can federate with this datacenter. The
      # secret contains all the information secondary datacenters need to contact
      # and authenticate with this datacenter. This should only be set to true
      # in your primary datacenter. The secret name is
      # `<global.name>-federation` (if setting `global.name`), otherwise
      # `<helm-release-name>-consul-federation`. Requires consul-k8s 0.15.0+.
      createFederationSecret: false

    # The lifecycle sidecar ensures the Consul services
    # are always registered with their local Consul clients and is used by the
    # ingress/terminating/mesh gateways as well as with every Connect-injected service.
    # @recurse: false
    # @type: map
    lifecycleSidecarContainer:
      resources:
        requests:
          memory: "25Mi"
          cpu: "10m"
        limits:
          memory: "100Mi"
          cpu: "1"

    # The name (and tag) of the Envoy Docker image used for the
    # connect-injected sidecar proxies and mesh, terminating, and ingress gateways.
    # See https://www.consul.io/docs/connect/proxies/envoy for full compatibility matrix between Consul and Envoy.
    # @default: envoyproxy/envoy-alpine:<latest supported version>
    imageEnvoy: "envoyproxy/envoy:v1.23.1"

    # Configuration for running this Helm chart on the Red Hat OpenShift platform.
    # This Helm chart currently supports OpenShift v4.x+.
    openshift:
      # If true, the Helm chart will create necessary configuration for running
      # its components on OpenShift.
      enabled: false

    # [Enterprise Only] This value refers to a Kubernetes secret that you have created
    # that contains your enterprise license. It is required if you are using an
    # enterprise binary. Defining it here applies it to your cluster once a leader
    # has been elected. If you are not using an enterprise image or if you plan to
    # introduce the license key via another route, then set these fields to null.
    # Note: the job to apply license runs on both Helm installs and upgrades.
    enterpriseLicense:
      # The name of the Kubernetes secret that holds the enterprise license.
      # The secret must be in the same namespace that Consul is installed into.
      secretName: null
      # The key within the Kubernetes secret that holds the enterprise license.
      secretKey: null

  # Server, when enabled, configures a server cluster to run. This should
  # be disabled if you plan on connecting to a Consul cluster external to
  # the Kube cluster.
  server:

    # If true, the chart will install all the resources necessary for a
    # Consul server cluster. If you're running Consul externally and want agents
    # within Kubernetes to join that cluster, this should probably be false.
    # @default: global.enabled
    # @type: boolean
    enabled: "-"

    # The name of the Docker image (including any tag) for the containers running
    # Consul server agents.
    # @type: string
    image: null

    # The number of server agents to run. This determines the fault tolerance of
    # the cluster. Please see the deployment table (https://consul.io/docs/internals/consensus#deployment-table)
    # for more information.
    replicas: 1

    # The number of servers that are expected to be running.
    # It defaults to server.replicas.
    # In most cases the default should be used, however if there are more
    # servers in this datacenter than server.replicas it might make sense
    # to override the default. This would be the case if two kube clusters
    # were joined into the same datacenter and each cluster ran a certain number
    # of servers.
    # @type: int
    bootstrapExpect: null

    # Exposes the servers' gossip and RPC ports as hostPorts. To enable a client
    # agent outside of the k8s cluster to join the datacenter, you would need to
    # enable `server.exposeGossipAndRPCPorts`, `client.exposeGossipPorts`, and
    # set `server.ports.serflan.port` to a port not being used on the host. Since
    # `client.exposeGossipPorts` uses the hostPort 8301,
    # `server.ports.serflan.port` must be set to something other than 8301.
    exposeGossipAndRPCPorts: false

    # Configures ports for the consul servers.
    ports:
      # Configures the LAN gossip port for the consul servers. If you choose to
      # enable `server.exposeGossipAndRPCPorts` and `client.exposeGossipPorts`,
      # that will configure the LAN gossip ports on the servers and clients to be
      # hostPorts, so if you are running clients and servers on the same node the
      # ports will conflict if they are both 8301.  When you enable
      # `server.exposeGossipAndRPCPorts` and `client.exposeGossipPorts`, you must
      # change this from the default to an unused port on the host, e.g. 9301. By
      # default the LAN gossip port is 8301 and configured as a containerPort on
      # the consul server Pods.
      serflan:
        port: 8301

    # This defines the disk size for configuring the
    # servers' StatefulSet storage. For dynamically provisioned storage classes, this is the
    # desired size. For manually defined persistent volumes, this should be set to
    # the disk size of the attached volume.
    storage: 4.9Gi

    # The StorageClass to use for the servers' StatefulSet storage. It must be
    # able to be dynamically provisioned if you want the storage
    # to be automatically created. For example, to use local
    # (https://kubernetes.io/docs/concepts/storage/storage-classes/#local)
    # storage classes, the PersistentVolumeClaims would need to be manually created.
    # A `null` value will use the Kubernetes cluster's default StorageClass. If a default
    # StorageClass does not exist, you will need to create one.
    # @type: string
    storageClass: local-storage

    # This will enable/disable Connect (https://consul.io/docs/connect). Setting this to true
    # _will not_ automatically secure pod communication, this
    # setting will only enable usage of the feature. Consul will automatically initialize
    # a new CA and set of certificates. Additional Connect settings can be configured
    # by setting the `server.extraConfig` value.
    connect: true

    # The resource requests (CPU, memory, etc.)
    # for each of the server agents. This should be a YAML map corresponding to a Kubernetes
    # ResourceRequirements (https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.11/#resourcerequirements-v1-core)
    # object. NOTE: The use of a YAML string is deprecated.
    #
    # Example:
    #
    # ```yaml
    # resources:
    #   requests:
    #     memory: '100Mi'
    #     cpu: '100m'
    #   limits:
    #     memory: '100Mi'
    #     cpu: '100m'
    # ```
    #
    # @recurse: false
    # @type: map
    resources:
      requests:
        memory: "50Mi"
        cpu: "10m"
      limits:
        memory: "100Mi"
        cpu: "1"

    # The security context for the server pods. This should be a YAML map corresponding to a
    # Kubernetes [SecurityContext](https://kubernetes.io/docs/tasks/configure-pod-container/security-context/) object.
    # By default, servers will run as non-root, with user ID `100` and group ID `1000`,
    # which correspond to the consul user and group created by the Consul docker image.
    # Note: if running on OpenShift, this setting is ignored because the user and group are set automatically
    # by the OpenShift platform.
    # @type: map
    # @recurse: false
    securityContext:
      runAsNonRoot: true
      runAsGroup: 1000
      runAsUser: 100
      fsGroup: 1000

    # This value is used to carefully
    # control a rolling update of Consul server agents. This value specifies the
    # partition (https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#partitions)
    # for performing a rolling update. Please read the linked Kubernetes documentation
    # and https://www.consul.io/docs/k8s/upgrade#upgrading-consul-servers for more information.
    updatePartition: 0

    # This configures the PodDisruptionBudget (https://kubernetes.io/docs/tasks/run-application/configure-pdb/)
    # for the server cluster.
    disruptionBudget:
      # This will enable/disable registering a PodDisruptionBudget for the server
      # cluster. If this is enabled, it will only register the budget so long as
      # the server cluster is enabled.
      enabled: true

      # The maximum number of unavailable pods. By default, this will be
      # automatically computed based on the `server.replicas` value to be `(n/2)-1`.
      # If you need to set this to `0`, you will need to add a
      # --set 'server.disruptionBudget.maxUnavailable=0'` flag to the helm chart installation
      # command because of a limitation in the Helm templating language.
      # @type: integer
      maxUnavailable: null

    # A raw string of extra JSON configuration (https://consul.io/docs/agent/options) for Consul
    # servers. This will be saved as-is into a ConfigMap that is read by the Consul
    # server agents. This can be used to add additional configuration that
    # isn't directly exposed by the chart.
    #
    # Example:
    #
    # ```yaml
    # extraConfig: |
    #   {
    #     "log_level": "DEBUG"
    #   }
    # ```
    #
    # This can also be set using Helm's `--set` flag using the following syntax:
    #
    # ```shell
    # --set 'server.extraConfig="{"log_level": "DEBUG"}"'
    # ```
    extraConfig: |
      {}

    # A list of extra volumes to mount for server agents. This
    # is useful for bringing in extra data that can be referenced by other configurations
    # at a well known path, such as TLS certificates or Gossip encryption keys. The
    # value of this should be a list of objects.
    #
    # Example:
    #
    # ```yaml
    # extraVolumes:
    #   - type: secret
    #     name: consul-certs
    #     load: false
    # ```
    #
    # Each object supports the following keys:
    #
    # - `type` - Type of the volume, must be one of "configMap" or "secret". Case sensitive.
    #
    # - `name` - Name of the configMap or secret to be mounted. This also controls
    #   the path that it is mounted to. The volume will be mounted to `/consul/userconfig/<name>`.
    #
    # - `load` - If true, then the agent will be
    #   configured to automatically load HCL/JSON configuration files from this volume
    #   with `-config-dir`. This defaults to false.
    #
    # @type: array<map>
    extraVolumes: []

    # This value defines the affinity (https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity)
    # for server pods. It defaults to allowing only a single server pod on each node, which
    # minimizes risk of the cluster becoming unusable if a node is lost. If you need
    # to run more pods per node (for example, testing on Minikube), set this value
    # to `null`.
    #
    # Example:
    #
    # ```yaml
    # affinity: |
    #   podAntiAffinity:
    #     requiredDuringSchedulingIgnoredDuringExecution:
    #       - labelSelector:
    #           matchLabels:
    #             app: {{ template "consul.name" . }}
    #             release: "{{ .Release.Name }}"
    #             component: server
    #       topologyKey: kubernetes.io/hostname
    # ```
    affinity: |
      podAntiAffinity:
        requiredDuringSchedulingIgnoredDuringExecution:
          - labelSelector:
              matchLabels:
                app: consul
                release: consul
                component: server
            topologyKey: kubernetes.io/hostname

    # Toleration settings for server pods. This
    # should be a multi-line string matching the Tolerations
    # (https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/) array in a Pod spec.
    tolerations: ""

    # This value defines `nodeSelector` (https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#nodeselector)
    # labels for server pod assignment, formatted as a multi-line string.
    #
    # Example:
    #
    # ```yaml
    # nodeSelector: |
    #   beta.kubernetes.io/arch: amd64
    # ```
    #
    # @type: string
    nodeSelector: null

    # This value references an existing
    # Kubernetes `priorityClassName` (https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/#pod-priority)
    # that can be assigned to server pods.
    priorityClassName: ""

    # Extra labels to attach to the server pods. This should be a YAML map.
    #
    # Example:
    #
    # ```yaml
    # extraLabels:
    #   labelKey: label-value
    #   anotherLabelKey: another-label-value
    # ```
    #
    # @type: map
    extraLabels: null

    # This value defines additional annotations for
    # server pods. This should be formatted as a multi-line string.
    #
    # ```yaml
    # annotations: |
    #   "sample/annotation1": "foo"
    #   "sample/annotation2": "bar"
    # ```
    #
    # @type: string
    annotations: null

    # Server service properties.
    service:
      # Annotations to apply to the server service.
      #
      # ```yaml
      # annotations: |
      #   "annotation-key": "annotation-value"
      # ```
      #
      # @type: string
      annotations: null

    # A list of extra environment variables to set within the stateful set.
    # These could be used to include proxy settings required for cloud auto-join
    # feature, in case kubernetes cluster is behind egress http proxies. Additionally,
    # it could be used to configure custom consul parameters.
    # @type: map
    extraEnvironmentVars: {}

  # Configuration for Consul servers when the servers are running outside of Kubernetes.
  # When running external servers, configuring these values is recommended
  # if setting `global.tls.enableAutoEncrypt` to true (requires consul-k8s >= 0.13.0)
  # or `global.acls.manageSystemACLs` to true (requires consul-k8s >= 0.14.0).
  externalServers:
    # If true, the Helm chart will be configured to talk to the external servers.
    # If setting this to true, you must also set `server.enabled` to false.
    enabled: false

    # An array of external Consul server hosts that are used to make
    # HTTPS connections from the components in this Helm chart.
    # Valid values include IPs, DNS names, or Cloud auto-join string.
    # The port must be provided separately below.
    # Note: `client.join` must also be set to the hosts that should be
    # used to join the cluster. In most cases, the `client.join` values
    # should be the same, however, they may be different if you
    # wish to use separate hosts for the HTTPS connections.
    # @type: array<string>
    hosts: []

    # The HTTPS port of the Consul servers.
    httpsPort: 8501

    # The server name to use as the SNI host header when connecting with HTTPS.
    # @type: string
    tlsServerName: null

    # If true, consul-k8s components will ignore the CA set in
    # `global.tls.caCert` when making HTTPS calls to Consul servers and
    # will instead use the consul-k8s image's system CAs for TLS verification.
    # If false, consul-k8s components will use `global.tls.caCert` when
    # making HTTPS calls to Consul servers.
    # **NOTE:** This does not affect Consul's internal RPC communication which will
  tests:
    enabled: true


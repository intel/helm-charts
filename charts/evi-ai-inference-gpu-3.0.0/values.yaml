# INTEL CONFIDENTIAL
#
# Copyright (C) 2022-2024 Intel Corporation.
#
# This software and the related documents are Intel copyrighted materials, and your use of
# them is governed by the express license under which they were provided to you (License).
# Unless the License provides otherwise, you may not use, modify, copy, publish, distribute,
# disclose or transmit this software or the related documents without Intel's prior written permission.
#
# This software and the related documents are provided as is, with no express or implied warranties,
# other than those that are expressly stated in the License.

---
# Default values for ai-inference-gpu.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.
replicaCount: 1

global:
  namespace:
    create: false
    value: hce-ai
    istioInjection:
      create: false
  service:
    name: evi-ai-inference
  deployment:
    name: evi-ai-inference
  secret:
    minio:
      name: evi-minio-secret

istioInjection: true

configMap:
  AIInference:
    name: ai-inference
    value: configs/AiInference.config
    maxConcurrentWorkloadPerReplica: 8
  hbaseStorage:
    name: hbase-storage
    value: configs/hbase_storage_configmap.json
    hbaseAddr: "my-hbase-hbase-master.dev"
    hbasePort: 9090
    storageRestAddress: "storage-rest.storage-rest"
    storageRestPort: "9900"
  mediaStorage:
    name: media-storage
    value: configs/media_storage_configmap.json
    rootUser: ""
    rootPassword: ""
    secretMountPath: /opt/hce-configs/credentials/minio
    rootUserMountPath: /opt/hce-configs/credentials/minio/rootUser
    rootPasswordMountPath: /opt/hce-configs/credentials/minio/rootPassword
    minIOAddress: "minio-service.minio"
    minIOPort: "9000"


image:
  repository: ai-inference-gpu
  Version: latest
  pullPolicy: IfNotPresent
  restfulPort: 50051
  grpcPort: 50052

resources:
  requests:
    cpu: 10m
    memory: 300Mi
    gpuNum: 1
  limits:
    cpu: 120
    memory: 128Gi
    gpuNum: 1

